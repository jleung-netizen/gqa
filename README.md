An autoregressive decoding project that incorporates efficient attention mechanisms, including group-query attention and KV-caching, to balance computational cost and model expressiveness. This approach enabled the model to generate next-operation tokens for Common Intermediate Language (CIL) with a validation loss of less than 0.08, running exclusively on CPU.
